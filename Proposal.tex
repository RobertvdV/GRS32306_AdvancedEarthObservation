\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage[colorlinks, allcolors=blue]{hyperref}
\bibliographystyle{apalike}
\title{Accessing Digital Elevation Models with different image overlap using photogrammetry}
\author{Robert Vlasakker, van de}
\date{April 2021}

\begin{document}

\maketitle

\section{Introduction}
With the development of cheap Unmanned Aerial Vehicles (UAV) photogrammetry has become more and more popular. 
UAV's come with high resolution cameras, GNSS and are available almost anywhere these days.
Photogrammetry is the process of reconstructing spatial information with images through computer vision. 
The process uses similar points visible on multiple images to determine the points in space.
So the reconstruction process is strongly dependent on the overlap between different images. 
When a point is visible on more images, the reconstruction certainty we be higher.
This is especially the case with the reconstruction of irregular formed object like vegetation \citep{AccessingImageOverlap}.
With irregular objects, a higher overlap is preferred to capture each side of the object.
If parts of the object are not visible on the image, they will not be reconstructed in the point cloud.
So the overlap strongly influences the point cloud density in the dense cloud \citep{OptimalAltOverWeath}.


\section{Problem Statement}
While UAV's do come with high resolution sensors and relatively cheap, small, high capacity batteries are not available \citep{UAVpopularity}.
A high image overlap takes longer to gather than a low image overlap. 
A drone can use a higher altitude so the sensor captures a larger area.
however, with a higher flight altitude the detail of the image will be less than that of a drone with a lower flight altitude.
This way the gathering process takes longer, and the UAV might even need to switch batteries instead of taking the images in a single flight.
In the reconstruction process, a high overlap will also result in longer computation time \citep{AccessingImageOverlap}
However, a higher image overlap, does not automatically results in a higher point accuracy (x,y,z) \citep{EffectofUABimgcamover}.
By investigating how reducing the image overlap influences photogrammetry results, time and computing power may be saved without loosing too much spatial information.
% Needed to set 3. at new page

\section{Research Questions} 

\emph{How is the result of the Digital Elevation Model influenced by reducing the image overlap by using the Metashape 'Reduce Overlap' function?}

\section{Methods}
For this research a data set from the Advanced Earth Observation will be used, the 'Koyage' data set along with Agisoft Metashape (1.6.5.)
This data set contains 111 images with a resolution of 4000 x 3000, the images all contain WGS84 coordinates with the image location. 
The images will first be aligned to generate a dense cloud (medium quality, no depth filtering).
Next, a mesh will be created, this is needed for Metashape to calculate the images that can be left out.
For the mesh the dense cloud will be used as source and the mesh will be a height field (2.5).
A high face count (653.852 faces) will be used.

The 'Reduce Overlap' function will be used on all three settings (low, medium and high) to reduce the amount of images. 
The dense cloud with be built again with the images selecting by the 'Reduce Overlap' function.
The dense cloud will again be build at medium setting and no depth filtering
Next a Digital Elevation Model (DEM) will be built using the Metashape software.
For the DEM the dense cloud will be used as source data and interpolation will be used in case the point cloud contains bad/missing data.
This process will be repeated three times with 'Reduce Overlap' on low, medium and high settings.
Finally the different DEM's will be visually inspected and compared (e.g. using the difference). 
The research will take place in the two last weeks of April 2021.

\bibliography{bibliography}
\end{document}
